name: analyze-and-update-sheets

on:
  workflow_dispatch:
  schedule:
    - cron: "30 23 * * *" # KST 08:30

permissions:
  contents: read
  actions: read

jobs:
  run:
    runs-on: ubuntu-latest
    timeout-minutes: 150
    env:
      CI: "1"
      PYTHONUNBUFFERED: "1"
      TZ: "Asia/Seoul"
      SHEET_ID: ${{ secrets.SHEET_ID }}
      SA_JSON: ${{ secrets.GDRIVE_SA_JSON }}
      SOURCE_REPO_PAT: ${{ secrets.SOURCE_REPO_PAT }}
      SRC_REPO: "ckh3455/file-automation"
      SRC_WORKFLOW: "molit.yml"
      SRC_ARTIFACT: "molit-xlsx"

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Install jq
        run: |
          sudo apt-get update
          sudo apt-get install -y jq

      - name: Download artifacts with freshness guard (retry)
        id: fetch
        shell: bash
        env:
          MAX_TRIES: "6"
          RETRY_MIN: "15"
        run: |
          set -euo pipefail
          echo "${SOURCE_REPO_PAT}" | gh auth login --with-token

          rm -rf artifacts
          mkdir -p artifacts

          try=1
          while :; do
            echo "::group::[try ${try}] locate latest SUCCESS run"
            RUN_JSON="$(gh run list -R "${SRC_REPO}" \
              --workflow "${SRC_WORKFLOW}" \
              --status success \
              --json databaseId,displayTitle,updatedAt \
              --limit 1)"
            echo "RUN_JSON=${RUN_JSON}"
            RUN_ID="$(echo "${RUN_JSON}" | jq -r '.[0].databaseId // empty')"
            RUN_UPDATED="$(echo "${RUN_JSON}" | jq -r '.[0].updatedAt // empty')"
            RUN_TITLE="$(echo "${RUN_JSON}" | jq -r '.[0].displayTitle // empty')"
            echo "RUN_ID=${RUN_ID}"
            echo "RUN_UPDATED(UTC)=${RUN_UPDATED}"
            echo "RUN_TITLE=${RUN_TITLE}"
            echo "::endgroup::"

            rc=0
            if [ -z "${RUN_ID}" ]; then
              echo "::warning::no successful run found yet."
              rc=66
            else
              echo "::group::download artifact ${SRC_ARTIFACT} (run ${RUN_ID})"
              rm -rf artifacts/*
              if ! gh run download "${RUN_ID}" -R "${SRC_REPO}" -n "${SRC_ARTIFACT}" -D artifacts; then
                echo "::warning::artifact download failed."
                rc=66
              fi
              echo "::endgroup::"
            fi

            if [ ${rc} -eq 0 ]; then
              echo "::group::freshness check (<=12h, KST)"
              python - <<'PY'
import pathlib, sys, datetime, re
root = pathlib.Path("artifacts")
files = sorted(root.rglob("*.xlsx"), key=lambda p: p.stat().st_mtime)
kst_now = datetime.datetime.utcnow() + datetime.timedelta(hours=9)
today = kst_now.date()
print(f"KST now: {kst_now}  (today={today})")
print(f"files: {len(files)}")
if not files:
    print("NO XLSX FILES in artifacts directory.")
    sys.exit(66)

def kst(ts):
    return datetime.datetime.utcfromtimestamp(ts) + datetime.timedelta(hours=9)

for p in files[-15:]:
    mod = kst(p.stat().st_mtime)
    age = (kst_now - mod).total_seconds()/3600
    print(f"- {p} | modified(KST)={mod} | age_h={age:.2f}")

latest = files[-1]
mod = kst(latest.stat().st_mtime)
age = (kst_now - mod).total_seconds()/3600
print(f"latest: {latest} | modified(KST)={mod} | age_h={age:.2f}")

m = re.findall(r'(20\d{2})[-_/ ]?(\d{1,2})[-_/ ]?(\d{1,2})', latest.name)
if m:
    y, M, d = map(int, m[-1])
    hint = datetime.date(y, M, d)
    print(f"filename date hint: {hint} (diff_days={(today-hint).days})")

if age > 12:
    print("RESULT: STALE or NOT TODAY → retry later")
    sys.exit(66)
print("RESULT: FRESH ✓")
PY
              rc=$?
              echo "::endgroup::"
            fi

            if [ ${rc} -eq 0 ]; then
              echo "fresh artifacts detected."
              break
            fi

            if [ ${try} -ge ${MAX_TRIES} ]; then
              echo "::error::no fresh artifacts after ${try} tries."
              exit 1
            fi

            echo "::notice::stale or not ready. retry in ${RETRY_MIN} minutes (next try: $((try+1))/${MAX_TRIES})."
            sleep "$((RETRY_MIN*60))"
            try=$((try+1))
          done

          echo "OK" > .fresh_ok

      - name: List downloaded files
        run: |
          find artifacts -type f -printf "%TY-%Tm-%Td %TT %p\n" | sort || true

      - name: Run analysis & update
        if: ${{ hashFiles('.fresh_ok') != '' }}
        env:
          ARTIFACTS_DIR: artifacts
        run: |
          python scripts/analyze_and_update.py \
            --artifacts-dir artifacts \
            --sheet-id "$SHEET_ID"

      - name: Preview analyze_report (always)
        if: always()
        run: |
          echo "== analyze_report tree =="; ls -alR analyze_report || true
          echo "---- latest.log (head) ----"; sed -n '1,220p' analyze_report/latest.log || true
          echo "---- run logs list ----"; ls -al analyze_report/run-*.log 2>/dev/null || true
          echo "---- where_written.txt ----"; cat analyze_report/where_written.txt 2>/dev/null || true

      - name: Upload report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: analyze-report
          path: analyze_report/**
          retention-days: 14
          compression-level: 6
