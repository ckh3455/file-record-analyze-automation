# .github/workflows/analyze-and-update-sheets.yml
name: analyze-and-update-sheets

on:
  workflow_dispatch:
  schedule:
    - cron: "30 23 * * *"  # KST 08:30

permissions:
  contents: read
  actions: read

jobs:
  run:
    runs-on: ubuntu-latest
    timeout-minutes: 150
    env:
      CI: "1"
      PYTHONUNBUFFERED: "1"
      TZ: Asia/Seoul

      SHEET_ID: ${{ secrets.SHEET_ID }}
      SA_JSON:  ${{ secrets.GDRIVE_SA_JSON }}
      SOURCE_REPO_PAT: ${{ secrets.SOURCE_REPO_PAT }}

      # ì™¸ë¶€ ë ˆí¬/ì›Œí¬í”Œë¡œ/ì•„í‹°íŒ©íŠ¸ ì„¤ì •
      SRC_REPO: ckh3455/file-automation
      SRC_WORKFLOW: molit.yml
      SRC_ARTIFACT: molit-xlsx

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # âœ… ì•„í‹°íŒ©íŠ¸ ë‹¤ìš´ë¡œë“œ(ì •í™•ëª… ìš°ì„ , ì‹¤íŒ¨ ì‹œ ì „ë¶€), KST 12h ì‹ ì„ ë„, 15ë¶„ ê°„ê²© ì¬ì‹œë„
      - name: Download artifacts with freshness guard (retry every 15 min)
        id: fetch
        shell: bash
        env:
          MAX_TRIES: "6"    # ì²˜ìŒ + 5íšŒ ì¬ì‹œë„
          RETRY_MIN: "15"   # 15ë¶„ ê°„ê²©
        run: |
          set -euo pipefail
          echo "${SOURCE_REPO_PAT}" | gh auth login --with-token

          rm -rf artifacts
          mkdir -p artifacts

          try=1
          while :; do
            echo "::group::[try ${try}] find latest SUCCESS run"
            RUN_JSON="$(gh run list -R "${SRC_REPO}" \
              --workflow "${SRC_WORKFLOW}" \
              --status success \
              --json databaseId,displayTitle,updatedAt \
              --limit 1)"
            echo "RUN_JSON=${RUN_JSON}"
            RUN_ID="$(echo "${RUN_JSON}" | jq -r '.[0].databaseId // empty')"
            RUN_UPDATED="$(echo "${RUN_JSON}" | jq -r '.[0].updatedAt // empty')"
            RUN_TITLE="$(echo "${RUN_JSON}" | jq -r '.[0].displayTitle // empty')"
            echo "RUN_ID=${RUN_ID}"
            echo "RUN_UPDATED(UTC)=${RUN_UPDATED}"
            echo "RUN_TITLE=${RUN_TITLE}"
            echo "::endgroup::"

            rc=0
            if [ -z "${RUN_ID}" ]; then
              echo "::warning::No successful run found yet."
              rc=66
            else
              echo "::group::List artifacts of the run"
              ART_NAMES="$(gh api repos/${SRC_REPO}/actions/runs/${RUN_ID}/artifacts --jq '.artifacts[].name')"
              echo "Artifacts on run ${RUN_ID}:"
              echo "${ART_NAMES:-<none>}"
              echo "::endgroup::"

              rm -rf artifacts/*

              # 1) ì •í™•í•œ ì´ë¦„ ìš°ì„ 
              if grep -Fxq "${SRC_ARTIFACT}" <<<"${ART_NAMES}"; then
                echo "::group::Download artifact (exact): ${SRC_ARTIFACT}"
                gh run download "${RUN_ID}" -R "${SRC_REPO}" -n "${SRC_ARTIFACT}" -D artifacts || rc=66
                echo "::endgroup::"
              else
                echo "::notice::Artifact '${SRC_ARTIFACT}' not found on run ${RUN_ID}. Fallback to download all artifacts."
                # 2) ëª¨ë“  ì•„í‹°íŒ©íŠ¸ ë‹¤ìš´ë¡œë“œ â†’ .xlsx ê²€ì‚¬
                if [ -n "${ART_NAMES}" ]; then
                  while IFS= read -r NAME; do
                    [ -z "${NAME}" ] && continue
                    echo "::group::Download artifact (fallback): ${NAME}"
                    gh run download "${RUN_ID}" -R "${SRC_REPO}" -n "${NAME}" -D artifacts || true
                    echo "::endgroup::"
                  done <<< "${ART_NAMES}"
                else
                  echo "::warning::This run has zero artifacts."
                fi
              fi

              XLSX_COUNT="$(find artifacts -type f -name '*.xlsx' | wc -l | tr -d ' ')"
              if [ "${XLSX_COUNT}" -eq 0 ]; then
                echo "::warning::No .xlsx found after download. Will retry."
                rc=66
              else
                echo "::notice::Downloaded ${XLSX_COUNT} xlsx file(s)."
              fi
            fi

            # ğŸ” Bash-only freshness check (<=12h, KST)
            if [ ${rc} -eq 0 ]; then
              echo "::group::Freshness check (<=12h, KST, bash-only)"
              KST_NOW_SEC=$(( $(date -u +%s) + 9*3600 ))
              mapfile -t LINES < <(find artifacts -type f -name '*.xlsx' -printf '%T@ %p\n' | sort -n)
              echo "xlsx files found: ${#LINES[@]}"

              if [ "${#LINES[@]}" -eq 0 ]; then
                echo "No .xlsx after download â†’ treat as stale"
                rc=66
              else
                LAST_LINE="${LINES[-1]}"
                LAST_TS_FLOAT="${LAST_LINE%% *}"
                LAST_FILE="${LAST_LINE#* }"
                LAST_TS_INT="${LAST_TS_FLOAT%.*}"
                LAST_AGE_SEC=$(( KST_NOW_SEC - LAST_TS_INT ))
                LAST_AGE_H=$(echo "$LAST_AGE_SEC/3600" | bc -l)

                echo "latest: ${LAST_FILE}"
                echo "latest age hours: ${LAST_AGE_H}"

                # 12h(43200s) ê¸°ì¤€
                if [ "$LAST_AGE_SEC" -gt 43200 ]; then
                  echo "RESULT: STALE or NOT TODAY â†’ retry later"
                  rc=66
                else
                  echo "RESULT: FRESH âœ“"
                  rc=0
                fi
              fi
              echo "::endgroup::"
            fi

            if [ ${rc} -eq 0 ]; then
              echo "Fresh artifacts detected."
              break
            fi

            if [ ${try} -ge ${MAX_TRIES} ]; then
              echo "::error::No fresh artifacts after ${try} tries."
              exit 1
            fi

            echo "::notice::Retry in ${RETRY_MIN} minutes (next try: $((try+1))/${MAX_TRIES})."
            sleep "$((RETRY_MIN*60))"
            try=$((try+1))
          done

          echo "OK" > .fresh_ok

      - name: List downloaded files
        run: |
          find artifacts -type f -printf "%TY-%Tm-%Td %TT %p\n" | sort || true

      - name: Run analysis & update
        if: ${{ hashFiles('.fresh_ok') != '' }}
        env:
          ARTIFACTS_DIR: artifacts
        run: |
          python scripts/analyze_and_update.py \
            --artifacts-dir artifacts \
            --sheet-id "$SHEET_ID"

      - name: Preview analyze_report (always)
        if: always()
        run: |
          echo "== analyze_report tree =="; ls -alR analyze_report || true
          echo "---- latest.log (head) ----"; sed -n '1,220p' analyze_report/latest.log || true
          echo "---- run logs list ----"; ls -al analyze_report/run-*.log 2>/dev/null || true
          echo "---- where_written.txt ----"; cat analyze_report/where_written.txt 2>/dev/null || true

      - name: Upload report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: analyze-report
          path: analyze_report/**
          retention-days: 14
          compression-level: 6
