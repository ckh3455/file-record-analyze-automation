name: analyze-and-update-sheets

on:
  workflow_dispatch:
  schedule:
    - cron: "30 23 * * *"  # KST 08:30

permissions:
  contents: read
  actions: read

jobs:
  run:
    runs-on: ubuntu-latest
    timeout-minutes: 150
    env:
      CI: "1"
      PYTHONUNBUFFERED: "1"
      TZ: Asia/Seoul
      SHEET_ID: ${{ secrets.SHEET_ID }}
      SA_JSON: ${{ secrets.GDRIVE_SA_JSON }}
      SOURCE_REPO_PAT: ${{ secrets.SOURCE_REPO_PAT }}
      SRC_REPO: ckh3455/file-automation
      SRC_WORKFLOW: molit.yml
      SRC_ARTIFACT: molit-xlsx

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # 최신 성공 run의 artifact 다운로드 + 신선도(<=12h) 검사 + 15분 간격 재시도(최대 6회)
      - name: Download artifacts with freshness guard (retry)
        id: fetch
        shell: bash
        env:
          MAX_TRIES: "6"
          RETRY_MIN: "15"
        run: |
          set -euo pipefail

          echo "::group::Authenticate gh"
          echo "${SOURCE_REPO_PAT}" | gh auth login --with-token
          gh --version
          echo "::endgroup::"

          rm -rf artifacts
          mkdir -p artifacts

          try=1
          while :; do
            echo "::group::[try ${try}] locate latest SUCCESS run"
            RUN_JSON="$(gh run list -R "${SRC_REPO}" \
              --workflow "${SRC_WORKFLOW}" \
              --status success \
              --json databaseId,displayTitle,updatedAt \
              --limit 1 || true)"
            echo "RUN_JSON=${RUN_JSON}"
            RUN_ID="$(echo "${RUN_JSON}" | jq -r '.[0].databaseId // empty')"
            RUN_UPDATED="$(echo "${RUN_JSON}" | jq -r '.[0].updatedAt // empty')"
            RUN_TITLE="$(echo "${RUN_JSON}" | jq -r '.[0].displayTitle // empty')"
            echo "RUN_ID=${RUN_ID}"
            echo "RUN_UPDATED(UTC)=${RUN_UPDATED}"
            echo "RUN_TITLE=${RUN_TITLE}"
            echo "::endgroup::"

            rc=0
            if [ -z "${RUN_ID}" ]; then
              echo "::warning::no successful run found yet."
              rc=66
            else
              echo "::group::download artifact ${SRC_ARTIFACT} (run ${RUN_ID})"
              rm -rf artifacts/*
              if ! gh run download "${RUN_ID}" -R "${SRC_REPO}" -n "${SRC_ARTIFACT}" -D artifacts; then
                echo "::warning::artifact download failed."
                rc=66
              fi
              echo "::endgroup::"
            fi

            # 신선도(<=12h)와 상세 로그
            if [ ${rc} -eq 0 ]; then
              echo "::group::Freshness check (<=12h, KST)"
              file_count=$(find artifacts -type f -name '*.xlsx' | wc -l | tr -d ' ')
              echo "xlsx files in artifacts: ${file_count}"
              if [ "${file_count}" = "0" ]; then
                echo "NO XLSX FILES in artifacts directory."
                rc=66
              else
                # 최신 파일 찾기(수정시간 기준)
                latest_line="$(find artifacts -type f -name '*.xlsx' -printf '%T@ %p\n' | sort -n | tail -1)"
                latest_path="${latest_line#* }"
                latest_epoch_utc="$(stat -c %Y "${latest_path}")"
                now_utc="$(date -u +%s)"
                kst_now=$(( now_utc + 9*3600 ))
                age_sec=$(( kst_now - latest_epoch_utc ))
                # 로그 보기 좋게
                mod_utc_str="$(date -u -d @"${latest_epoch_utc}" '+%F %T')"
                mod_kst_str="$(date -u -d "$((latest_epoch_utc+9*3600))" '+%F %T')"
                printf 'Latest: %s | mtime(UTC)=%s | mtime(KST)=%s | age_hours=%.2f\n' \
                  "${latest_path}" "${mod_utc_str}" "${mod_kst_str}" "$(awk "BEGIN{print ${age_sec}/3600}")"

                # 파일명에서 날짜 힌트 로그(있으면)
                base="$(basename "${latest_path}")"
                if echo "${base}" | grep -Eq '20[0-9]{2}[-_/ ]?[0-9]{1,2}[-_/ ]?[0-9]{1,2}'; then
                  y=$(echo "${base}" | sed -nE 's/.*(20[0-9]{2})[-_/ ]?([0-9]{1,2})[-_/ ]?([0-9]{1,2}).*/\1/p')
                  M=$(echo "${base}" | sed -nE 's/.*(20[0-9]{2})[-_/ ]?([0-9]{1,2})[-_/ ]?([0-9]{1,2}).*/\2/p')
                  d=$(echo "${base}" | sed -nE 's/.*(20[0-9]{2})[-_/ ]?([0-9]{1,2})[-_/ ]?([0-9]{1,2}).*/\3/p')
                  echo "filename date hint: ${y}-${M}-${d}"
                fi

                if [ "${age_sec}" -gt $((12*3600)) ]; then
                  echo "RESULT: STALE or NOT TODAY → retry later"
                  rc=66
                else
                  echo "RESULT: FRESH ✓"
                fi
              fi
              echo "::endgroup::"
            fi

            if [ ${rc} -eq 0 ]; then
              echo "fresh artifacts detected."
              break
            fi

            if [ ${try} -ge ${MAX_TRIES} ]; then
              echo "::error::no fresh artifacts after ${try} tries."
              exit 1
            fi

            echo "::notice::stale or not ready. retry in ${RETRY_MIN} minutes (next try: $((try+1))/${MAX_TRIES})."
            sleep "$((RETRY_MIN*60))"
            try=$((try+1))
          done

          echo "OK" > .fresh_ok

      - name: List downloaded files
        run: |
          find artifacts -type f -printf "%TY-%Tm-%Td %TT %p\n" | sort || true

      - name: Run analysis & update
        if: ${{ hashFiles('.fresh_ok') != '' }}
        env:
          ARTIFACTS_DIR: artifacts
        run: |
          python scripts/analyze_and_update.py \
            --artifacts-dir artifacts \
            --sheet-id "$SHEET_ID"

      - name: Preview analyze_report (always)
        if: always()
        run: |
          echo "== analyze_report tree =="; ls -alR analyze_report || true
          echo "---- latest.log (head) ----"; sed -n '1,220p' analyze_report/latest.log || true
          echo "---- run logs list ----"; ls -al analyze_report/run-*.log 2>/dev/null || true
          echo "---- where_written.txt ----"; cat analyze_report/where_written.txt 2>/dev/null || true

      - name: Upload report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: analyze-report
          path: analyze_report/**
          retention-days: 14
          compression-level: 6
